{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_B_WnWvmarB",
        "outputId": "c153cdf4-1d71-40b7-ebc3-aac8f1e55794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random as python_random\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Embedding, LSTM, Dropout, Bidirectional\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "IW_pgooNAa9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "bMHCfuoFKcPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_corpus(corpus_file):\n",
        "    '''Read in review data set and returns docs and labels'''\n",
        "    documents = []\n",
        "    labels = []\n",
        "    with open(corpus_file, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            tokens = line.strip()\n",
        "            documents.append(\" \".join(tokens.split()[3:]).strip())\n",
        "            # 6-class problem: books, camera, dvd, health, music, software\n",
        "            labels.append(tokens.split()[0])\n",
        "    return documents, labels\n",
        "    \n",
        "def read_embeddings(embeddings_file):\n",
        "    '''Read in word embeddings from file and save as numpy array'''\n",
        "    embeddings = json.load(open(embeddings_file, 'r'))\n",
        "    return {word: np.array(embeddings[word]) for word in embeddings}\n",
        "\n",
        "def get_emb_matrix(voc, emb):\n",
        "    '''Get embedding matrix given vocab and the embeddings'''\n",
        "    num_tokens = len(voc) + 2\n",
        "    word_index = dict(zip(voc, range(len(voc))))\n",
        "    # Bit hacky, get embedding dimension from the word \"the\"\n",
        "    embedding_dim = len(emb[\"the\"])\n",
        "    # Prepare embedding matrix to the correct size\n",
        "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = emb.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    # Final matrix with pretrained embeddings that we can feed to embedding layer\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "iaoOnEqAAiNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train, Y_train, X_dev, Y_dev, batch_size, epochs):\n",
        "    '''Train the model here. Note the different settings you can experiment with!'''\n",
        "    # Potentially change these to cmd line args again\n",
        "    # And yes, don't be afraid to experiment!\n",
        "    verbose = 1\n",
        "    batch_size = batch_size\n",
        "    epochs = epochs\n",
        "    # Early stopping: stop training when there are three consecutive epochs without improving\n",
        "    # It's also possible to monitor the training loss with monitor=\"loss\"\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    # Finally fit the model to our data\n",
        "    model.fit(X_train, Y_train, verbose=verbose, epochs=epochs, callbacks=[callback], batch_size=batch_size, validation_data=(X_dev, Y_dev))\n",
        "    # Print final accuracy for the model (clearer overview)\n",
        "    test_set_predict(model, X_dev, Y_dev, \"dev\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "yl4xOcqIA-sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_set_predict(model, X_test, Y_test, ident):\n",
        "    '''Do predictions and measure accuracy on our own test set (that we split off train)'''\n",
        "    # Get predictions using the trained model\n",
        "    Y_pred = model.predict(X_test)\n",
        "    # Finally, convert to numerical labels to get scores with sklearn\n",
        "    Y_pred = np.argmax(Y_pred, axis=1)\n",
        "    # If you have gold data, you can calculate accuracy\n",
        "    Y_test = np.argmax(Y_test, axis=1)\n",
        "    print('Accuracy on own {1} set: {0}'.format(round(accuracy_score(Y_test, Y_pred), 3), ident))"
      ],
      "metadata": {
        "id": "BeLpGXCTBEiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "-3LPyLnAJHjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data files paths\n",
        "train_set = '/content/gdrive/MyDrive/LFD-AS3/train.txt'\n",
        "test_set = '/content/gdrive/MyDrive/LFD-AS3/test.txt'\n",
        "val_set = '/content/gdrive/MyDrive/LFD-AS3/val.txt'\n",
        "emb = '/content/gdrive/MyDrive/LFD-AS3/glove_reviews.json'"
      ],
      "metadata": {
        "id": "2wBUAgvUEwEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading training data\n",
        "X_train, Y_train = read_corpus(train_set)\n",
        "# reading validation data\n",
        "X_dev, Y_dev = read_corpus(val_set)\n",
        "# reading embeddings\n",
        "embeddings = read_embeddings(emb)"
      ],
      "metadata": {
        "id": "7yzNHrWeJNgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text vectorizing + embedding loading + labels encoding"
      ],
      "metadata": {
        "id": "pKAFlGAgS6Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform words to indices using a vectorizer\n",
        "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
        "# Use train and dev to create vocab - could also do just train\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_dev)\n",
        "vectorizer.adapt(text_ds)\n",
        "# Dictionary mapping words to idx\n",
        "voc = vectorizer.get_vocabulary()\n",
        "emb_matrix = get_emb_matrix(voc, embeddings)\n",
        "\n",
        "# Transform string labels to one-hot encodings\n",
        "encoder = LabelBinarizer()\n",
        "Y_train_bin = encoder.fit_transform(Y_train)  # Use encoder.classes_ to find mapping back\n",
        "Y_dev_bin = encoder.fit_transform(Y_dev)\n",
        "\n",
        "# Transform input to vectorized input\n",
        "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
        "X_dev_vect = vectorizer(np.array([[s] for s in X_dev])).numpy()\n",
        "\n",
        "# Read in test set and vectorize\n",
        "X_test, Y_test = read_corpus(test_set)\n",
        "Y_test_bin = encoder.fit_transform(Y_test)\n",
        "X_test_vect = vectorizer(np.array([[s] for s in X_test])).numpy()"
      ],
      "metadata": {
        "id": "z8wb1juxS1yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base model: training + testing"
      ],
      "metadata": {
        "id": "2TO8ce61TlSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1: One LSTM layer"
      ],
      "metadata": {
        "id": "17W6tzpiFbVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KBQYqtbBJh7",
        "outputId": "1e801f62-cf6a-4908-b92e-cbebb47a55ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 48s 176ms/step - loss: 1.7449 - accuracy: 0.2818 - val_loss: 1.6965 - val_accuracy: 0.4045\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 45s 170ms/step - loss: 1.5271 - accuracy: 0.4609 - val_loss: 1.2433 - val_accuracy: 0.5239\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 45s 171ms/step - loss: 1.1493 - accuracy: 0.5626 - val_loss: 0.9301 - val_accuracy: 0.6477\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 45s 171ms/step - loss: 0.8938 - accuracy: 0.6588 - val_loss: 0.8456 - val_accuracy: 0.6864\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 45s 170ms/step - loss: 0.7456 - accuracy: 0.7256 - val_loss: 0.9572 - val_accuracy: 0.6341\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 45s 171ms/step - loss: 0.6515 - accuracy: 0.7618 - val_loss: 0.6036 - val_accuracy: 0.7795\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 46s 173ms/step - loss: 0.5648 - accuracy: 0.8137 - val_loss: 0.6450 - val_accuracy: 0.7898\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 46s 174ms/step - loss: 0.5435 - accuracy: 0.8128 - val_loss: 0.5289 - val_accuracy: 0.8341\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 46s 173ms/step - loss: 0.5005 - accuracy: 0.8336 - val_loss: 0.8385 - val_accuracy: 0.7455\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 46s 173ms/step - loss: 0.4794 - accuracy: 0.8379 - val_loss: 0.5977 - val_accuracy: 0.8057\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 46s 175ms/step - loss: 0.4508 - accuracy: 0.8479 - val_loss: 0.4692 - val_accuracy: 0.8489\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 47s 178ms/step - loss: 0.4213 - accuracy: 0.8628 - val_loss: 1.0284 - val_accuracy: 0.6830\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 49s 187ms/step - loss: 0.4039 - accuracy: 0.8675 - val_loss: 0.4545 - val_accuracy: 0.8625\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 50s 191ms/step - loss: 0.3882 - accuracy: 0.8720 - val_loss: 0.4592 - val_accuracy: 0.8580\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 50s 190ms/step - loss: 0.3858 - accuracy: 0.8777 - val_loss: 0.4899 - val_accuracy: 0.8409\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 51s 192ms/step - loss: 0.3805 - accuracy: 0.8756 - val_loss: 0.4526 - val_accuracy: 0.8477\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 50s 189ms/step - loss: 0.3658 - accuracy: 0.8799 - val_loss: 0.5645 - val_accuracy: 0.8170\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 50s 188ms/step - loss: 0.3565 - accuracy: 0.8865 - val_loss: 0.3636 - val_accuracy: 0.8886\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 50s 190ms/step - loss: 0.3447 - accuracy: 0.8851 - val_loss: 0.4868 - val_accuracy: 0.8284\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 50s 191ms/step - loss: 0.3308 - accuracy: 0.8863 - val_loss: 0.3450 - val_accuracy: 0.9000\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 50s 190ms/step - loss: 0.3223 - accuracy: 0.8972 - val_loss: 0.4850 - val_accuracy: 0.8489\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 50s 191ms/step - loss: 0.3459 - accuracy: 0.8874 - val_loss: 0.8307 - val_accuracy: 0.7443\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 51s 193ms/step - loss: 0.3128 - accuracy: 0.9007 - val_loss: 0.3815 - val_accuracy: 0.8852\n",
            "Accuracy on own dev set: 0.885\n",
            "Accuracy on own test set: 0.867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2: One LSTM layer + trainable embedding layer"
      ],
      "metadata": {
        "id": "AJ5s1qwQEQ5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=True))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJjznk70GcfY",
        "outputId": "8ecbf5ad-3dc2-431e-c702-1b7e3a70cae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 74s 274ms/step - loss: 1.7447 - accuracy: 0.2813 - val_loss: 1.6956 - val_accuracy: 0.3977\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 64s 242ms/step - loss: 1.5255 - accuracy: 0.4611 - val_loss: 1.2417 - val_accuracy: 0.5227\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 66s 248ms/step - loss: 1.1486 - accuracy: 0.5649 - val_loss: 0.9241 - val_accuracy: 0.6557\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 63s 240ms/step - loss: 0.8934 - accuracy: 0.6609 - val_loss: 0.9020 - val_accuracy: 0.6602\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 63s 240ms/step - loss: 0.7472 - accuracy: 0.7220 - val_loss: 0.8802 - val_accuracy: 0.6557\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 64s 243ms/step - loss: 0.6496 - accuracy: 0.7666 - val_loss: 0.5615 - val_accuracy: 0.8068\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 66s 248ms/step - loss: 0.5624 - accuracy: 0.8055 - val_loss: 0.4937 - val_accuracy: 0.8409\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 63s 240ms/step - loss: 0.5301 - accuracy: 0.8145 - val_loss: 0.4593 - val_accuracy: 0.8489\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 64s 244ms/step - loss: 0.4984 - accuracy: 0.8346 - val_loss: 0.9261 - val_accuracy: 0.7398\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.4786 - accuracy: 0.8370 - val_loss: 0.6127 - val_accuracy: 0.7864\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 68s 257ms/step - loss: 0.4445 - accuracy: 0.8547 - val_loss: 0.4903 - val_accuracy: 0.8386\n",
            "Accuracy on own dev set: 0.839\n",
            "Accuracy on own test set: 0.832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 3: One LSTM layer + one Dense layer between the embedding and the LSTM layers"
      ],
      "metadata": {
        "id": "AAvfCWT-Acdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim))\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GogbG3QLAbk1",
        "outputId": "fa306214-0ca2-44ff-e04a-2afb0f1a0a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 73s 269ms/step - loss: 1.7367 - accuracy: 0.2787 - val_loss: 1.6720 - val_accuracy: 0.3841\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 70s 265ms/step - loss: 1.4396 - accuracy: 0.4493 - val_loss: 1.2202 - val_accuracy: 0.4977\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 68s 259ms/step - loss: 1.1497 - accuracy: 0.5555 - val_loss: 1.0211 - val_accuracy: 0.6398\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 68s 258ms/step - loss: 0.9200 - accuracy: 0.6422 - val_loss: 0.7346 - val_accuracy: 0.7614\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 67s 256ms/step - loss: 0.7107 - accuracy: 0.7443 - val_loss: 0.6868 - val_accuracy: 0.7420\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 67s 255ms/step - loss: 0.6218 - accuracy: 0.7756 - val_loss: 0.6174 - val_accuracy: 0.7875\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 0.5508 - accuracy: 0.8111 - val_loss: 0.7337 - val_accuracy: 0.7511\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 0.5170 - accuracy: 0.8218 - val_loss: 0.5012 - val_accuracy: 0.8398\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.4771 - accuracy: 0.8417 - val_loss: 0.7559 - val_accuracy: 0.7545\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 0.4712 - accuracy: 0.8427 - val_loss: 0.5417 - val_accuracy: 0.8261\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 67s 255ms/step - loss: 0.4395 - accuracy: 0.8621 - val_loss: 0.5463 - val_accuracy: 0.8170\n",
            "Accuracy on own dev set: 0.817\n",
            "Accuracy on own test set: 0.818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tanh activation function"
      ],
      "metadata": {
        "id": "r2CQBVVwGVJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"tanh\"))\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP4lrTMtFtDW",
        "outputId": "d0f31936-c042-4d41-f8bb-ccd1f2a4f64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 66s 244ms/step - loss: 1.7473 - accuracy: 0.2661 - val_loss: 1.6964 - val_accuracy: 0.3614\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 65s 248ms/step - loss: 1.4966 - accuracy: 0.4254 - val_loss: 1.7159 - val_accuracy: 0.3148\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 1.2184 - accuracy: 0.5232 - val_loss: 1.0447 - val_accuracy: 0.5909\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 68s 256ms/step - loss: 0.9945 - accuracy: 0.6043 - val_loss: 0.8152 - val_accuracy: 0.7307\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 66s 249ms/step - loss: 0.7932 - accuracy: 0.7059 - val_loss: 0.7640 - val_accuracy: 0.6886\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 66s 249ms/step - loss: 0.6759 - accuracy: 0.7566 - val_loss: 0.5704 - val_accuracy: 0.7955\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 64s 243ms/step - loss: 0.6004 - accuracy: 0.7912 - val_loss: 0.6227 - val_accuracy: 0.7909\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 66s 248ms/step - loss: 0.5482 - accuracy: 0.8152 - val_loss: 0.4936 - val_accuracy: 0.8500\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 65s 247ms/step - loss: 0.5238 - accuracy: 0.8232 - val_loss: 0.8222 - val_accuracy: 0.7182\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 64s 243ms/step - loss: 0.5092 - accuracy: 0.8294 - val_loss: 0.7465 - val_accuracy: 0.7580\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 65s 245ms/step - loss: 0.4845 - accuracy: 0.8408 - val_loss: 0.6347 - val_accuracy: 0.7864\n",
            "Accuracy on own dev set: 0.786\n",
            "Accuracy on own test set: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### relu activation function"
      ],
      "metadata": {
        "id": "Q3x9h2uRGb1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8EFsFu6jQuG",
        "outputId": "5d95f46c-75a3-43f0-e5e7-81d20d3a22e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 63s 231ms/step - loss: 1.7730 - accuracy: 0.2156 - val_loss: 1.7499 - val_accuracy: 0.3057\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 60s 228ms/step - loss: 1.7037 - accuracy: 0.3453 - val_loss: 1.6079 - val_accuracy: 0.3989\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 61s 229ms/step - loss: 1.4107 - accuracy: 0.4050 - val_loss: 1.2690 - val_accuracy: 0.5114\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 61s 230ms/step - loss: 1.2469 - accuracy: 0.4874 - val_loss: 1.1541 - val_accuracy: 0.4784\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 61s 230ms/step - loss: 1.0362 - accuracy: 0.5900 - val_loss: 0.8441 - val_accuracy: 0.7057\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 60s 229ms/step - loss: 0.8197 - accuracy: 0.6699 - val_loss: 0.8363 - val_accuracy: 0.6375\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 61s 231ms/step - loss: 0.6346 - accuracy: 0.7704 - val_loss: 0.6260 - val_accuracy: 0.7784\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 61s 230ms/step - loss: 0.5363 - accuracy: 0.8118 - val_loss: 0.4341 - val_accuracy: 0.8670\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 61s 229ms/step - loss: 0.4546 - accuracy: 0.8481 - val_loss: 0.4443 - val_accuracy: 0.8602\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 60s 229ms/step - loss: 0.4258 - accuracy: 0.8559 - val_loss: 1.1667 - val_accuracy: 0.6068\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 61s 229ms/step - loss: 0.3866 - accuracy: 0.8746 - val_loss: 0.4865 - val_accuracy: 0.8489\n",
            "Accuracy on own dev set: 0.849\n",
            "Accuracy on own test set: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sigmoid activation function"
      ],
      "metadata": {
        "id": "5EAS8PmpGh_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"sigmoid\"))\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9DZHbMj3_j1",
        "outputId": "ccbf3072-ab20-430a-898a-9cfa65df021a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 65s 241ms/step - loss: 1.8067 - accuracy: 0.1784 - val_loss: 1.7928 - val_accuracy: 0.1648\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 61s 233ms/step - loss: 1.8009 - accuracy: 0.1827 - val_loss: 1.8071 - val_accuracy: 0.2091\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7943 - accuracy: 0.1848 - val_loss: 1.7930 - val_accuracy: 0.1636\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 60s 227ms/step - loss: 1.7876 - accuracy: 0.1941 - val_loss: 1.7907 - val_accuracy: 0.1716\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7819 - accuracy: 0.1953 - val_loss: 1.7841 - val_accuracy: 0.1875\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7774 - accuracy: 0.2000 - val_loss: 1.7658 - val_accuracy: 0.2000\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7670 - accuracy: 0.2182 - val_loss: 1.7733 - val_accuracy: 0.2102\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7513 - accuracy: 0.2393 - val_loss: 1.7530 - val_accuracy: 0.1739\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7397 - accuracy: 0.2336 - val_loss: 1.8469 - val_accuracy: 0.1727\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7256 - accuracy: 0.2422 - val_loss: 1.7389 - val_accuracy: 0.1830\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 60s 226ms/step - loss: 1.7043 - accuracy: 0.2709 - val_loss: 1.8158 - val_accuracy: 0.1784\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 62s 235ms/step - loss: 1.6813 - accuracy: 0.2739 - val_loss: 1.5585 - val_accuracy: 0.3636\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 60s 229ms/step - loss: 1.6565 - accuracy: 0.2836 - val_loss: 1.6158 - val_accuracy: 0.2534\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 60s 228ms/step - loss: 1.6457 - accuracy: 0.2929 - val_loss: 1.9109 - val_accuracy: 0.1648\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 61s 229ms/step - loss: 1.6574 - accuracy: 0.2938 - val_loss: 1.6635 - val_accuracy: 0.2545\n",
            "Accuracy on own dev set: 0.255\n",
            "Accuracy on own test set: 0.278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "softmax activation function"
      ],
      "metadata": {
        "id": "hCsPPKKkGpXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"softmax\"))\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t98pC0_g97Dl",
        "outputId": "ebecdb38-394f-44fe-9a37-571b954520f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 65s 238ms/step - loss: 1.7923 - accuracy: 0.1590 - val_loss: 1.7917 - val_accuracy: 0.1716\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 62s 235ms/step - loss: 1.7923 - accuracy: 0.1687 - val_loss: 1.7917 - val_accuracy: 0.1682\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 62s 236ms/step - loss: 1.7923 - accuracy: 0.1664 - val_loss: 1.7917 - val_accuracy: 0.1682\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 63s 239ms/step - loss: 1.7923 - accuracy: 0.1649 - val_loss: 1.7918 - val_accuracy: 0.1716\n",
            "Accuracy on own dev set: 0.172\n",
            "Accuracy on own test set: 0.171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 4: Extra LSTM layers"
      ],
      "metadata": {
        "id": "WIp4uYlIbGE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One extra LSTM layer"
      ],
      "metadata": {
        "id": "0cdot4xJHJUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, return_sequences=True))\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqIZsTlJIZzP",
        "outputId": "2b03acd6-b961-4594-b003-c23d9558189d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 129s 476ms/step - loss: 1.7773 - accuracy: 0.2130 - val_loss: 1.7573 - val_accuracy: 0.3341\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 118s 448ms/step - loss: 1.6835 - accuracy: 0.3583 - val_loss: 1.4323 - val_accuracy: 0.4216\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 117s 445ms/step - loss: 1.3912 - accuracy: 0.3983 - val_loss: 1.2605 - val_accuracy: 0.4580\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 117s 444ms/step - loss: 1.2380 - accuracy: 0.4756 - val_loss: 1.1447 - val_accuracy: 0.4795\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 118s 448ms/step - loss: 0.9846 - accuracy: 0.6076 - val_loss: 0.9101 - val_accuracy: 0.6057\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 118s 446ms/step - loss: 0.7356 - accuracy: 0.7159 - val_loss: 0.6141 - val_accuracy: 0.7909\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 117s 442ms/step - loss: 0.5717 - accuracy: 0.7924 - val_loss: 0.5943 - val_accuracy: 0.8011\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 117s 441ms/step - loss: 0.4823 - accuracy: 0.8351 - val_loss: 0.4195 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 116s 439ms/step - loss: 0.4228 - accuracy: 0.8557 - val_loss: 0.6099 - val_accuracy: 0.8034\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 117s 442ms/step - loss: 0.3986 - accuracy: 0.8678 - val_loss: 0.6929 - val_accuracy: 0.7477\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 117s 445ms/step - loss: 0.3662 - accuracy: 0.8794 - val_loss: 0.4913 - val_accuracy: 0.8364\n",
            "Accuracy on own dev set: 0.836\n",
            "Accuracy on own test set: 0.852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two extra LSTM layers"
      ],
      "metadata": {
        "id": "dmLf2FA-HPVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, return_sequences=True))\n",
        "    model.add(LSTM(embedding_dim, return_sequences=True))\n",
        "    model.add(LSTM(embedding_dim))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WrAPCH1Ippd",
        "outputId": "8aa7acbb-735c-41a3-d66e-027a1bb97b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 177s 653ms/step - loss: 1.7829 - accuracy: 0.1934 - val_loss: 1.7681 - val_accuracy: 0.2886\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 171s 649ms/step - loss: 1.7129 - accuracy: 0.3424 - val_loss: 1.4704 - val_accuracy: 0.3761\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 171s 649ms/step - loss: 1.4181 - accuracy: 0.3787 - val_loss: 1.2568 - val_accuracy: 0.4693\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 172s 651ms/step - loss: 1.1986 - accuracy: 0.4813 - val_loss: 0.9516 - val_accuracy: 0.6341\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 172s 651ms/step - loss: 0.9281 - accuracy: 0.6291 - val_loss: 0.8137 - val_accuracy: 0.7034\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 172s 650ms/step - loss: 0.7035 - accuracy: 0.7419 - val_loss: 0.7151 - val_accuracy: 0.7068\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 172s 650ms/step - loss: 0.5860 - accuracy: 0.7886 - val_loss: 0.6009 - val_accuracy: 0.7966\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 175s 663ms/step - loss: 0.5240 - accuracy: 0.8173 - val_loss: 0.4868 - val_accuracy: 0.8352\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 174s 658ms/step - loss: 0.4584 - accuracy: 0.8391 - val_loss: 0.4961 - val_accuracy: 0.8330\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 172s 652ms/step - loss: 0.4404 - accuracy: 0.8453 - val_loss: 0.5935 - val_accuracy: 0.7864\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 173s 656ms/step - loss: 0.4034 - accuracy: 0.8597 - val_loss: 0.5466 - val_accuracy: 0.8261\n",
            "Accuracy on own dev set: 0.826\n",
            "Accuracy on own test set: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 5: Dropout and Recurrent Dropout"
      ],
      "metadata": {
        "id": "J1dncBxCbRHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropout = 0.1"
      ],
      "metadata": {
        "id": "SqCe7oLQHpAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.1))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SdjLu0Wmg1n",
        "outputId": "c5f1fdea-ba24-431f-fcdb-838fb07f476a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 86s 317ms/step - loss: 1.7738 - accuracy: 0.2166 - val_loss: 1.7504 - val_accuracy: 0.3068\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 82s 312ms/step - loss: 1.7076 - accuracy: 0.3408 - val_loss: 1.6245 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 81s 307ms/step - loss: 1.4135 - accuracy: 0.4031 - val_loss: 1.2697 - val_accuracy: 0.5193\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 80s 304ms/step - loss: 1.2505 - accuracy: 0.4813 - val_loss: 1.1546 - val_accuracy: 0.4580\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 81s 306ms/step - loss: 1.0493 - accuracy: 0.5794 - val_loss: 0.8757 - val_accuracy: 0.6955\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 82s 309ms/step - loss: 0.8371 - accuracy: 0.6675 - val_loss: 0.7763 - val_accuracy: 0.6750\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 81s 308ms/step - loss: 0.6505 - accuracy: 0.7602 - val_loss: 0.6367 - val_accuracy: 0.7648\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 83s 316ms/step - loss: 0.5479 - accuracy: 0.8088 - val_loss: 0.4482 - val_accuracy: 0.8568\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 86s 324ms/step - loss: 0.4680 - accuracy: 0.8422 - val_loss: 0.5113 - val_accuracy: 0.8341\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 85s 322ms/step - loss: 0.4387 - accuracy: 0.8507 - val_loss: 1.0347 - val_accuracy: 0.6341\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 85s 321ms/step - loss: 0.3923 - accuracy: 0.8680 - val_loss: 0.4606 - val_accuracy: 0.8511\n",
            "Accuracy on own dev set: 0.851\n",
            "Accuracy on own test set: 0.853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropout = 0.2"
      ],
      "metadata": {
        "id": "-T-eMLnoHt6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.2))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA5_qavrszhU",
        "outputId": "a5c301dc-b306-43bf-dedc-6c458e4bb009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 67s 248ms/step - loss: 1.7749 - accuracy: 0.2076 - val_loss: 1.7511 - val_accuracy: 0.3091\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 68s 256ms/step - loss: 1.7123 - accuracy: 0.3348 - val_loss: 1.6413 - val_accuracy: 0.3886\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 1.4342 - accuracy: 0.4007 - val_loss: 1.3112 - val_accuracy: 0.5102\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 1.2527 - accuracy: 0.4773 - val_loss: 1.1639 - val_accuracy: 0.4432\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 1.0691 - accuracy: 0.5678 - val_loss: 0.8934 - val_accuracy: 0.6807\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 0.8475 - accuracy: 0.6590 - val_loss: 0.8338 - val_accuracy: 0.6432\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 0.6627 - accuracy: 0.7500 - val_loss: 0.7415 - val_accuracy: 0.7227\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 0.5603 - accuracy: 0.8021 - val_loss: 0.4452 - val_accuracy: 0.8602\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.4752 - accuracy: 0.8405 - val_loss: 0.5269 - val_accuracy: 0.8250\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 69s 261ms/step - loss: 0.4401 - accuracy: 0.8517 - val_loss: 1.1501 - val_accuracy: 0.6023\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 0.4007 - accuracy: 0.8652 - val_loss: 0.4646 - val_accuracy: 0.8523\n",
            "Accuracy on own dev set: 0.852\n",
            "Accuracy on own test set: 0.858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropout = 0.3"
      ],
      "metadata": {
        "id": "MrhjmpAWHxYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.3))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klSJWLDOw-AG",
        "outputId": "58655e52-e23f-4140-ae2e-c6ce0f2b5503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 70s 257ms/step - loss: 1.7759 - accuracy: 0.2097 - val_loss: 1.7517 - val_accuracy: 0.3057\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 1.7165 - accuracy: 0.3294 - val_loss: 1.6546 - val_accuracy: 0.3807\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 66s 251ms/step - loss: 1.4556 - accuracy: 0.3979 - val_loss: 1.2920 - val_accuracy: 0.5227\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 1.2630 - accuracy: 0.4739 - val_loss: 1.1682 - val_accuracy: 0.4364\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 66s 252ms/step - loss: 1.0862 - accuracy: 0.5618 - val_loss: 0.9164 - val_accuracy: 0.6602\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.8610 - accuracy: 0.6547 - val_loss: 0.8288 - val_accuracy: 0.6511\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.6806 - accuracy: 0.7448 - val_loss: 0.7341 - val_accuracy: 0.7250\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 67s 255ms/step - loss: 0.5699 - accuracy: 0.7945 - val_loss: 0.4620 - val_accuracy: 0.8511\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 0.4863 - accuracy: 0.8353 - val_loss: 0.4970 - val_accuracy: 0.8364\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 0.4489 - accuracy: 0.8464 - val_loss: 1.0637 - val_accuracy: 0.6261\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.4125 - accuracy: 0.8595 - val_loss: 0.4560 - val_accuracy: 0.8534\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 66s 251ms/step - loss: 0.3794 - accuracy: 0.8739 - val_loss: 0.5138 - val_accuracy: 0.8250\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 68s 256ms/step - loss: 0.3559 - accuracy: 0.8844 - val_loss: 0.4296 - val_accuracy: 0.8659\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.3502 - accuracy: 0.8815 - val_loss: 0.3935 - val_accuracy: 0.8750\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 67s 254ms/step - loss: 0.3371 - accuracy: 0.8922 - val_loss: 0.4477 - val_accuracy: 0.8614\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 68s 256ms/step - loss: 0.3350 - accuracy: 0.8924 - val_loss: 0.3548 - val_accuracy: 0.8920\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 67s 255ms/step - loss: 0.3073 - accuracy: 0.9026 - val_loss: 0.3877 - val_accuracy: 0.8773\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 65s 248ms/step - loss: 0.2909 - accuracy: 0.9050 - val_loss: 0.3684 - val_accuracy: 0.8886\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 65s 245ms/step - loss: 0.2960 - accuracy: 0.9026 - val_loss: 0.4041 - val_accuracy: 0.8727\n",
            "Accuracy on own dev set: 0.873\n",
            "Accuracy on own test set: 0.877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropout = 0.4"
      ],
      "metadata": {
        "id": "VZbnqrFdH3_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.4))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yXY1bVd4wMd",
        "outputId": "a80f7511-f764-48c1-aa2d-e301d3d90d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 66s 240ms/step - loss: 1.7771 - accuracy: 0.2078 - val_loss: 1.7523 - val_accuracy: 0.3068\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 64s 242ms/step - loss: 1.7203 - accuracy: 0.3218 - val_loss: 1.6660 - val_accuracy: 0.3761\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 64s 242ms/step - loss: 1.4709 - accuracy: 0.4036 - val_loss: 1.2804 - val_accuracy: 0.5148\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 63s 240ms/step - loss: 1.2680 - accuracy: 0.4713 - val_loss: 1.1716 - val_accuracy: 0.4261\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 63s 239ms/step - loss: 1.1025 - accuracy: 0.5545 - val_loss: 0.9883 - val_accuracy: 0.6216\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 65s 248ms/step - loss: 0.8896 - accuracy: 0.6448 - val_loss: 0.9564 - val_accuracy: 0.5807\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 65s 245ms/step - loss: 0.6990 - accuracy: 0.7358 - val_loss: 0.7200 - val_accuracy: 0.7239\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 0.5890 - accuracy: 0.7900 - val_loss: 0.4682 - val_accuracy: 0.8489\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 65s 246ms/step - loss: 0.5058 - accuracy: 0.8235 - val_loss: 0.5419 - val_accuracy: 0.8205\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 65s 245ms/step - loss: 0.4620 - accuracy: 0.8424 - val_loss: 0.9060 - val_accuracy: 0.6625\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 66s 248ms/step - loss: 0.4199 - accuracy: 0.8573 - val_loss: 0.4414 - val_accuracy: 0.8659\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 65s 245ms/step - loss: 0.3931 - accuracy: 0.8659 - val_loss: 0.5919 - val_accuracy: 0.7932\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 65s 246ms/step - loss: 0.3668 - accuracy: 0.8801 - val_loss: 0.4077 - val_accuracy: 0.8750\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 68s 257ms/step - loss: 0.3568 - accuracy: 0.8834 - val_loss: 0.4024 - val_accuracy: 0.8693\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 65s 245ms/step - loss: 0.3493 - accuracy: 0.8832 - val_loss: 0.3861 - val_accuracy: 0.8807\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 62s 237ms/step - loss: 0.3395 - accuracy: 0.8900 - val_loss: 0.3714 - val_accuracy: 0.8886\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 63s 240ms/step - loss: 0.3191 - accuracy: 0.8976 - val_loss: 0.3531 - val_accuracy: 0.8909\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 62s 234ms/step - loss: 0.2961 - accuracy: 0.9057 - val_loss: 0.3687 - val_accuracy: 0.8784\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 64s 241ms/step - loss: 0.3051 - accuracy: 0.8988 - val_loss: 0.4003 - val_accuracy: 0.8693\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 64s 241ms/step - loss: 0.2847 - accuracy: 0.9047 - val_loss: 0.3457 - val_accuracy: 0.8864\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 62s 236ms/step - loss: 0.2800 - accuracy: 0.9083 - val_loss: 0.4074 - val_accuracy: 0.8739\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 62s 234ms/step - loss: 0.2805 - accuracy: 0.9062 - val_loss: 0.3599 - val_accuracy: 0.8841\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 63s 238ms/step - loss: 0.2714 - accuracy: 0.9149 - val_loss: 0.3430 - val_accuracy: 0.8875\n",
            "Epoch 24/50\n",
            "264/264 [==============================] - 63s 240ms/step - loss: 0.2571 - accuracy: 0.9185 - val_loss: 0.4177 - val_accuracy: 0.8739\n",
            "Epoch 25/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 0.2548 - accuracy: 0.9152 - val_loss: 0.3409 - val_accuracy: 0.9000\n",
            "Epoch 26/50\n",
            "264/264 [==============================] - 65s 248ms/step - loss: 0.2447 - accuracy: 0.9209 - val_loss: 0.4549 - val_accuracy: 0.8602\n",
            "Epoch 27/50\n",
            "264/264 [==============================] - 66s 251ms/step - loss: 0.2489 - accuracy: 0.9239 - val_loss: 0.3267 - val_accuracy: 0.9091\n",
            "Epoch 28/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 0.2380 - accuracy: 0.9246 - val_loss: 0.3599 - val_accuracy: 0.8943\n",
            "Epoch 29/50\n",
            "264/264 [==============================] - 67s 253ms/step - loss: 0.2315 - accuracy: 0.9242 - val_loss: 0.3939 - val_accuracy: 0.8795\n",
            "Epoch 30/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 0.2223 - accuracy: 0.9268 - val_loss: 0.3211 - val_accuracy: 0.9045\n",
            "Epoch 31/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 0.2196 - accuracy: 0.9299 - val_loss: 0.3179 - val_accuracy: 0.9080\n",
            "Epoch 32/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 0.2209 - accuracy: 0.9322 - val_loss: 0.3133 - val_accuracy: 0.9045\n",
            "Epoch 33/50\n",
            "264/264 [==============================] - 66s 252ms/step - loss: 0.2099 - accuracy: 0.9315 - val_loss: 0.3226 - val_accuracy: 0.9080\n",
            "Epoch 34/50\n",
            "264/264 [==============================] - 66s 251ms/step - loss: 0.2042 - accuracy: 0.9358 - val_loss: 0.3090 - val_accuracy: 0.9170\n",
            "Epoch 35/50\n",
            "264/264 [==============================] - 67s 252ms/step - loss: 0.1934 - accuracy: 0.9393 - val_loss: 0.3140 - val_accuracy: 0.9091\n",
            "Epoch 36/50\n",
            "264/264 [==============================] - 67s 255ms/step - loss: 0.2020 - accuracy: 0.9322 - val_loss: 0.3234 - val_accuracy: 0.9114\n",
            "Epoch 37/50\n",
            "264/264 [==============================] - 67s 255ms/step - loss: 0.1822 - accuracy: 0.9431 - val_loss: 0.3894 - val_accuracy: 0.8841\n",
            "Accuracy on own dev set: 0.884\n",
            "Accuracy on own test set: 0.873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropout = 0.35"
      ],
      "metadata": {
        "id": "Q7AmzzpoH61m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CixfpLCzDbrd",
        "outputId": "3c8bbad7-6c70-45be-9518-f995b65328a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 64s 234ms/step - loss: 1.7765 - accuracy: 0.2076 - val_loss: 1.7520 - val_accuracy: 0.3080\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 66s 249ms/step - loss: 1.7180 - accuracy: 0.3265 - val_loss: 1.6597 - val_accuracy: 0.3784\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 66s 248ms/step - loss: 1.4579 - accuracy: 0.3962 - val_loss: 1.2929 - val_accuracy: 0.5216\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 66s 251ms/step - loss: 1.2836 - accuracy: 0.4730 - val_loss: 1.1732 - val_accuracy: 0.4284\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 65s 247ms/step - loss: 1.0949 - accuracy: 0.5569 - val_loss: 0.9378 - val_accuracy: 0.6580\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 66s 251ms/step - loss: 0.8740 - accuracy: 0.6536 - val_loss: 1.0154 - val_accuracy: 0.5614\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 66s 252ms/step - loss: 0.6926 - accuracy: 0.7429 - val_loss: 0.6967 - val_accuracy: 0.7318\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 66s 249ms/step - loss: 0.5801 - accuracy: 0.7908 - val_loss: 0.4576 - val_accuracy: 0.8557\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 65s 245ms/step - loss: 0.4953 - accuracy: 0.8306 - val_loss: 0.5267 - val_accuracy: 0.8318\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 65s 247ms/step - loss: 0.4563 - accuracy: 0.8455 - val_loss: 0.8223 - val_accuracy: 0.6977\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 65s 247ms/step - loss: 0.4143 - accuracy: 0.8614 - val_loss: 0.4512 - val_accuracy: 0.8534\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 65s 247ms/step - loss: 0.3867 - accuracy: 0.8709 - val_loss: 0.5614 - val_accuracy: 0.8057\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 65s 248ms/step - loss: 0.3625 - accuracy: 0.8813 - val_loss: 0.4327 - val_accuracy: 0.8705\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 64s 244ms/step - loss: 0.3528 - accuracy: 0.8806 - val_loss: 0.3982 - val_accuracy: 0.8716\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 65s 246ms/step - loss: 0.3458 - accuracy: 0.8858 - val_loss: 0.4020 - val_accuracy: 0.8807\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 0.3361 - accuracy: 0.8910 - val_loss: 0.3828 - val_accuracy: 0.8795\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 66s 249ms/step - loss: 0.3125 - accuracy: 0.9000 - val_loss: 0.3919 - val_accuracy: 0.8705\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 66s 248ms/step - loss: 0.2925 - accuracy: 0.9071 - val_loss: 0.3500 - val_accuracy: 0.8864\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 65s 247ms/step - loss: 0.3032 - accuracy: 0.9000 - val_loss: 0.3892 - val_accuracy: 0.8773\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 66s 249ms/step - loss: 0.2761 - accuracy: 0.9092 - val_loss: 0.3393 - val_accuracy: 0.8909\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 66s 250ms/step - loss: 0.2783 - accuracy: 0.9111 - val_loss: 0.3963 - val_accuracy: 0.8807\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 66s 251ms/step - loss: 0.2783 - accuracy: 0.9066 - val_loss: 0.3644 - val_accuracy: 0.8886\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 66s 249ms/step - loss: 0.2627 - accuracy: 0.9190 - val_loss: 0.3481 - val_accuracy: 0.8864\n",
            "Accuracy on own dev set: 0.886\n",
            "Accuracy on own test set: 0.892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recurrent dropout = 0.1"
      ],
      "metadata": {
        "id": "d4QTF5PqIArp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, recurrent_dropout=0.1))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOc2XDuSh7Vz",
        "outputId": "55f0023e-3bd4-4873-fe4b-cf50a2423a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 142s 528ms/step - loss: 1.7729 - accuracy: 0.2164 - val_loss: 1.7499 - val_accuracy: 0.3091\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 138s 522ms/step - loss: 1.7043 - accuracy: 0.3429 - val_loss: 1.6108 - val_accuracy: 0.4011\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 138s 522ms/step - loss: 1.4134 - accuracy: 0.4100 - val_loss: 1.2852 - val_accuracy: 0.5091\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 138s 524ms/step - loss: 1.2413 - accuracy: 0.4879 - val_loss: 1.1577 - val_accuracy: 0.4670\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 139s 525ms/step - loss: 1.0396 - accuracy: 0.5900 - val_loss: 0.8846 - val_accuracy: 0.6875\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 137s 519ms/step - loss: 0.8261 - accuracy: 0.6704 - val_loss: 0.7230 - val_accuracy: 0.7068\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 137s 520ms/step - loss: 0.6415 - accuracy: 0.7618 - val_loss: 0.7044 - val_accuracy: 0.7386\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 138s 521ms/step - loss: 0.5401 - accuracy: 0.8081 - val_loss: 0.4467 - val_accuracy: 0.8580\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 139s 527ms/step - loss: 0.4603 - accuracy: 0.8462 - val_loss: 0.4708 - val_accuracy: 0.8557\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 138s 522ms/step - loss: 0.4264 - accuracy: 0.8571 - val_loss: 1.1858 - val_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 137s 518ms/step - loss: 0.3860 - accuracy: 0.8751 - val_loss: 0.4639 - val_accuracy: 0.8580\n",
            "Accuracy on own dev set: 0.858\n",
            "Accuracy on own test set: 0.857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recurrent dropout = 0.2"
      ],
      "metadata": {
        "id": "rdr7EfVsIE7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, recurrent_dropout=0.2))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnukV_jWqSDO",
        "outputId": "91ee962b-9989-4853-a8f2-f149a20fea2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 153s 572ms/step - loss: 1.7729 - accuracy: 0.2164 - val_loss: 1.7500 - val_accuracy: 0.3080\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 140s 529ms/step - loss: 1.7046 - accuracy: 0.3445 - val_loss: 1.6116 - val_accuracy: 0.3989\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 136s 517ms/step - loss: 1.4098 - accuracy: 0.4062 - val_loss: 1.2633 - val_accuracy: 0.5102\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 139s 526ms/step - loss: 1.2489 - accuracy: 0.4872 - val_loss: 1.1559 - val_accuracy: 0.4705\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 138s 523ms/step - loss: 1.0471 - accuracy: 0.5829 - val_loss: 0.8930 - val_accuracy: 0.6739\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 138s 521ms/step - loss: 0.8292 - accuracy: 0.6732 - val_loss: 0.8896 - val_accuracy: 0.6091\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 138s 523ms/step - loss: 0.6402 - accuracy: 0.7659 - val_loss: 0.6949 - val_accuracy: 0.7523\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 137s 519ms/step - loss: 0.5503 - accuracy: 0.8071 - val_loss: 0.4313 - val_accuracy: 0.8693\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 144s 547ms/step - loss: 0.4624 - accuracy: 0.8450 - val_loss: 0.4593 - val_accuracy: 0.8523\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 144s 547ms/step - loss: 0.4285 - accuracy: 0.8562 - val_loss: 1.1514 - val_accuracy: 0.6182\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 136s 516ms/step - loss: 0.3902 - accuracy: 0.8727 - val_loss: 0.4258 - val_accuracy: 0.8625\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 142s 537ms/step - loss: 0.3635 - accuracy: 0.8806 - val_loss: 0.6063 - val_accuracy: 0.7841\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 141s 533ms/step - loss: 0.3463 - accuracy: 0.8882 - val_loss: 0.4239 - val_accuracy: 0.8670\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 136s 516ms/step - loss: 0.3347 - accuracy: 0.8886 - val_loss: 0.4390 - val_accuracy: 0.8580\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 141s 534ms/step - loss: 0.3248 - accuracy: 0.8998 - val_loss: 0.4038 - val_accuracy: 0.8761\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 139s 528ms/step - loss: 0.3138 - accuracy: 0.9012 - val_loss: 0.3598 - val_accuracy: 0.8818\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 142s 537ms/step - loss: 0.2916 - accuracy: 0.9055 - val_loss: 0.5340 - val_accuracy: 0.8318\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 138s 524ms/step - loss: 0.2830 - accuracy: 0.9147 - val_loss: 0.3809 - val_accuracy: 0.8795\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 142s 540ms/step - loss: 0.2814 - accuracy: 0.9064 - val_loss: 0.3458 - val_accuracy: 0.8955\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 138s 525ms/step - loss: 0.2582 - accuracy: 0.9147 - val_loss: 0.3490 - val_accuracy: 0.8920\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 142s 537ms/step - loss: 0.2468 - accuracy: 0.9244 - val_loss: 0.4635 - val_accuracy: 0.8670\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 142s 537ms/step - loss: 0.2533 - accuracy: 0.9185 - val_loss: 0.3361 - val_accuracy: 0.9011\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 137s 520ms/step - loss: 0.2420 - accuracy: 0.9242 - val_loss: 0.3585 - val_accuracy: 0.8886\n",
            "Epoch 24/50\n",
            "264/264 [==============================] - 141s 534ms/step - loss: 0.2215 - accuracy: 0.9332 - val_loss: 0.4267 - val_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "264/264 [==============================] - 137s 518ms/step - loss: 0.2354 - accuracy: 0.9258 - val_loss: 0.3569 - val_accuracy: 0.8920\n",
            "Accuracy on own dev set: 0.892\n",
            "Accuracy on own test set: 0.892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recurrent dropout = 0.3"
      ],
      "metadata": {
        "id": "ydkjHxH2IKsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, recurrent_dropout=0.3))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTMmIXfIqUu-",
        "outputId": "ce39fdcc-a8d0-4c64-aa83-79c5e9fea405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 144s 537ms/step - loss: 1.7729 - accuracy: 0.2164 - val_loss: 1.7500 - val_accuracy: 0.3068\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 138s 521ms/step - loss: 1.7049 - accuracy: 0.3457 - val_loss: 1.6144 - val_accuracy: 0.3966\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 145s 550ms/step - loss: 1.4074 - accuracy: 0.4059 - val_loss: 1.2801 - val_accuracy: 0.5125\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 142s 536ms/step - loss: 1.2383 - accuracy: 0.4820 - val_loss: 1.1574 - val_accuracy: 0.4614\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 144s 547ms/step - loss: 1.0492 - accuracy: 0.5879 - val_loss: 0.8794 - val_accuracy: 0.6807\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 141s 533ms/step - loss: 0.8379 - accuracy: 0.6687 - val_loss: 0.6943 - val_accuracy: 0.7216\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 148s 560ms/step - loss: 0.6483 - accuracy: 0.7602 - val_loss: 0.6817 - val_accuracy: 0.7500\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 143s 541ms/step - loss: 0.5638 - accuracy: 0.8021 - val_loss: 0.4359 - val_accuracy: 0.8614\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 145s 549ms/step - loss: 0.4677 - accuracy: 0.8438 - val_loss: 0.4620 - val_accuracy: 0.8523\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 141s 535ms/step - loss: 0.4310 - accuracy: 0.8555 - val_loss: 1.0041 - val_accuracy: 0.6591\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 147s 557ms/step - loss: 0.3925 - accuracy: 0.8685 - val_loss: 0.4278 - val_accuracy: 0.8659\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 142s 539ms/step - loss: 0.3661 - accuracy: 0.8791 - val_loss: 0.5752 - val_accuracy: 0.7909\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 145s 550ms/step - loss: 0.3499 - accuracy: 0.8884 - val_loss: 0.4152 - val_accuracy: 0.8625\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 144s 545ms/step - loss: 0.3417 - accuracy: 0.8870 - val_loss: 0.4142 - val_accuracy: 0.8682\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 141s 534ms/step - loss: 0.3268 - accuracy: 0.8986 - val_loss: 0.4007 - val_accuracy: 0.8795\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 147s 556ms/step - loss: 0.3161 - accuracy: 0.8948 - val_loss: 0.3763 - val_accuracy: 0.8761\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 141s 534ms/step - loss: 0.2960 - accuracy: 0.9062 - val_loss: 0.5895 - val_accuracy: 0.8273\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 142s 538ms/step - loss: 0.2840 - accuracy: 0.9114 - val_loss: 0.3940 - val_accuracy: 0.8807\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 144s 546ms/step - loss: 0.2880 - accuracy: 0.9038 - val_loss: 0.3474 - val_accuracy: 0.8966\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 145s 550ms/step - loss: 0.2620 - accuracy: 0.9126 - val_loss: 0.3542 - val_accuracy: 0.8920\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 142s 536ms/step - loss: 0.2497 - accuracy: 0.9190 - val_loss: 0.5533 - val_accuracy: 0.8420\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 145s 549ms/step - loss: 0.2601 - accuracy: 0.9182 - val_loss: 0.3476 - val_accuracy: 0.8920\n",
            "Accuracy on own dev set: 0.892\n",
            "Accuracy on own test set: 0.894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recurrent dropout = 0.35"
      ],
      "metadata": {
        "id": "sXScGI-DIOVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, recurrent_dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i5Z7WspqZU2",
        "outputId": "190e9fb3-0afb-4aec-bb62-af6909aa6c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 146s 544ms/step - loss: 1.7731 - accuracy: 0.2159 - val_loss: 1.7500 - val_accuracy: 0.3091\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 145s 550ms/step - loss: 1.7050 - accuracy: 0.3429 - val_loss: 1.6162 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 144s 547ms/step - loss: 1.4101 - accuracy: 0.4038 - val_loss: 1.2682 - val_accuracy: 0.5182\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 145s 550ms/step - loss: 1.2413 - accuracy: 0.4841 - val_loss: 1.1587 - val_accuracy: 0.4670\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 141s 536ms/step - loss: 1.0550 - accuracy: 0.5808 - val_loss: 0.9163 - val_accuracy: 0.6511\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 143s 542ms/step - loss: 0.8375 - accuracy: 0.6661 - val_loss: 0.7281 - val_accuracy: 0.7034\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 144s 546ms/step - loss: 0.6590 - accuracy: 0.7581 - val_loss: 0.6889 - val_accuracy: 0.7534\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 143s 543ms/step - loss: 0.5615 - accuracy: 0.8028 - val_loss: 0.4342 - val_accuracy: 0.8648\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 145s 551ms/step - loss: 0.4750 - accuracy: 0.8393 - val_loss: 0.4702 - val_accuracy: 0.8500\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 140s 531ms/step - loss: 0.4356 - accuracy: 0.8538 - val_loss: 0.9324 - val_accuracy: 0.6807\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 139s 528ms/step - loss: 0.3937 - accuracy: 0.8718 - val_loss: 0.4720 - val_accuracy: 0.8466\n",
            "Accuracy on own dev set: 0.847\n",
            "Accuracy on own test set: 0.853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recurrent dropout = 0.4"
      ],
      "metadata": {
        "id": "zm6cK0P_IRGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, recurrent_dropout=0.4))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDq4Zta2qbRx",
        "outputId": "5ac91c08-d363-4c43-ea12-8d1ba64e14d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 143s 535ms/step - loss: 1.7731 - accuracy: 0.2197 - val_loss: 1.7500 - val_accuracy: 0.3080\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 142s 538ms/step - loss: 1.7057 - accuracy: 0.3398 - val_loss: 1.6199 - val_accuracy: 0.3932\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 142s 539ms/step - loss: 1.4103 - accuracy: 0.4069 - val_loss: 1.2731 - val_accuracy: 0.5125\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 140s 531ms/step - loss: 1.2337 - accuracy: 0.4841 - val_loss: 1.1638 - val_accuracy: 0.4602\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 143s 540ms/step - loss: 1.0596 - accuracy: 0.5841 - val_loss: 0.9355 - val_accuracy: 0.6636\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 144s 545ms/step - loss: 0.8386 - accuracy: 0.6652 - val_loss: 0.7674 - val_accuracy: 0.6818\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 143s 543ms/step - loss: 0.6569 - accuracy: 0.7540 - val_loss: 0.6623 - val_accuracy: 0.7534\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 143s 540ms/step - loss: 0.5645 - accuracy: 0.8019 - val_loss: 0.4426 - val_accuracy: 0.8534\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 142s 540ms/step - loss: 0.4711 - accuracy: 0.8438 - val_loss: 0.4930 - val_accuracy: 0.8420\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 142s 538ms/step - loss: 0.4395 - accuracy: 0.8550 - val_loss: 1.0300 - val_accuracy: 0.6625\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 146s 552ms/step - loss: 0.3965 - accuracy: 0.8720 - val_loss: 0.5243 - val_accuracy: 0.8182\n",
            "Accuracy on own dev set: 0.818\n",
            "Accuracy on own test set: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recurrent dropout = 0.3 + dropout=0.35"
      ],
      "metadata": {
        "id": "PX6Yk08nIUBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, recurrent_dropout=0.3, dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_00qPncQ4EZ",
        "outputId": "b89d4074-9e30-43ac-dea2-46fa0f339e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 149s 555ms/step - loss: 1.7745 - accuracy: 0.2178 - val_loss: 1.7518 - val_accuracy: 0.3057\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 144s 545ms/step - loss: 1.7181 - accuracy: 0.3206 - val_loss: 1.6589 - val_accuracy: 0.3670\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 147s 557ms/step - loss: 1.4644 - accuracy: 0.4024 - val_loss: 1.2940 - val_accuracy: 0.5182\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 145s 548ms/step - loss: 1.2760 - accuracy: 0.4697 - val_loss: 1.1822 - val_accuracy: 0.4250\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 144s 545ms/step - loss: 1.1025 - accuracy: 0.5763 - val_loss: 0.9837 - val_accuracy: 0.6159\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 147s 556ms/step - loss: 0.8900 - accuracy: 0.6410 - val_loss: 0.7798 - val_accuracy: 0.6807\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 146s 552ms/step - loss: 0.7036 - accuracy: 0.7322 - val_loss: 0.6333 - val_accuracy: 0.7818\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 145s 549ms/step - loss: 0.5881 - accuracy: 0.7903 - val_loss: 0.4617 - val_accuracy: 0.8432\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 145s 548ms/step - loss: 0.5060 - accuracy: 0.8254 - val_loss: 0.5453 - val_accuracy: 0.8193\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 144s 545ms/step - loss: 0.4601 - accuracy: 0.8460 - val_loss: 0.9638 - val_accuracy: 0.6557\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 146s 554ms/step - loss: 0.4252 - accuracy: 0.8602 - val_loss: 0.4032 - val_accuracy: 0.8727\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 144s 547ms/step - loss: 0.3933 - accuracy: 0.8694 - val_loss: 0.5609 - val_accuracy: 0.8057\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 142s 540ms/step - loss: 0.3749 - accuracy: 0.8761 - val_loss: 0.3731 - val_accuracy: 0.8830\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 145s 550ms/step - loss: 0.3625 - accuracy: 0.8813 - val_loss: 0.4935 - val_accuracy: 0.8523\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 144s 544ms/step - loss: 0.3497 - accuracy: 0.8806 - val_loss: 0.3786 - val_accuracy: 0.8841\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 144s 547ms/step - loss: 0.3419 - accuracy: 0.8919 - val_loss: 0.4378 - val_accuracy: 0.8670\n",
            "Accuracy on own dev set: 0.867\n",
            "Accuracy on own test set: 0.871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### recurrent dropout = 0.1 + dropout=0.35"
      ],
      "metadata": {
        "id": "l42Ym4mCIcR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = 0.01\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, recurrent_dropout=0.1, dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(Y_train, emb_matrix)\n",
        "# Train the model\n",
        "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "# Finally do the predictions\n",
        "test_set_predict(model, X_test_vect, Y_test_bin, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHbzYlS7zmiM",
        "outputId": "3b3211da-9a1a-45ba-a39d-f9debb676de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "264/264 [==============================] - 152s 559ms/step - loss: 1.7738 - accuracy: 0.2182 - val_loss: 1.7516 - val_accuracy: 0.3080\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 159s 602ms/step - loss: 1.7176 - accuracy: 0.3204 - val_loss: 1.6587 - val_accuracy: 0.3750\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 158s 597ms/step - loss: 1.4558 - accuracy: 0.4045 - val_loss: 1.3070 - val_accuracy: 0.5091\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 156s 590ms/step - loss: 1.2647 - accuracy: 0.4858 - val_loss: 1.1721 - val_accuracy: 0.4409\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 150s 568ms/step - loss: 1.0939 - accuracy: 0.5727 - val_loss: 0.9185 - val_accuracy: 0.6409\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 159s 604ms/step - loss: 0.8732 - accuracy: 0.6464 - val_loss: 0.8504 - val_accuracy: 0.6216\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 162s 613ms/step - loss: 0.6834 - accuracy: 0.7453 - val_loss: 0.7675 - val_accuracy: 0.7182\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 161s 609ms/step - loss: 0.5745 - accuracy: 0.7974 - val_loss: 0.4615 - val_accuracy: 0.8398\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 159s 601ms/step - loss: 0.4928 - accuracy: 0.8273 - val_loss: 0.6185 - val_accuracy: 0.7955\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 155s 589ms/step - loss: 0.4531 - accuracy: 0.8488 - val_loss: 1.1945 - val_accuracy: 0.6091\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 152s 577ms/step - loss: 0.4239 - accuracy: 0.8604 - val_loss: 0.4371 - val_accuracy: 0.8545\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 154s 585ms/step - loss: 0.3808 - accuracy: 0.8739 - val_loss: 0.4857 - val_accuracy: 0.8273\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 149s 565ms/step - loss: 0.3650 - accuracy: 0.8827 - val_loss: 0.4552 - val_accuracy: 0.8534\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 149s 565ms/step - loss: 0.3651 - accuracy: 0.8758 - val_loss: 0.4517 - val_accuracy: 0.8568\n",
            "Accuracy on own dev set: 0.857\n",
            "Accuracy on own test set: 0.879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 6: Optimizers - learning rate"
      ],
      "metadata": {
        "id": "sRzg0vEfxob8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD Optimizer"
      ],
      "metadata": {
        "id": "jaWDAivKIqNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix, lr):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = lr\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lrs = [0.01, 0.03, 0.07, 0.1, 0.2, 0.5]\n",
        "for lr in lrs:\n",
        "  print(lr)\n",
        "  print(\"---\")\n",
        "  # Create model\n",
        "  model = create_model(Y_train, emb_matrix, lr)\n",
        "  # Train the model\n",
        "  model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "  # Finally do the predictions\n",
        "  test_set_predict(model, X_test_vect, Y_test_bin, \"test\")\n",
        "  print(\"---------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODsXgvXss1Dz",
        "outputId": "0d210d0a-58a9-4246-afd1-8a74a171ca6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 11s 10ms/step - loss: 1.7765 - accuracy: 0.2076 - val_loss: 1.7520 - val_accuracy: 0.3080\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.7180 - accuracy: 0.3265 - val_loss: 1.6597 - val_accuracy: 0.3784\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 11ms/step - loss: 1.4579 - accuracy: 0.3960 - val_loss: 1.2934 - val_accuracy: 0.5216\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 3s 13ms/step - loss: 1.2582 - accuracy: 0.4746 - val_loss: 1.1692 - val_accuracy: 0.4375\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.0899 - accuracy: 0.5585 - val_loss: 0.9460 - val_accuracy: 0.6557\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.8686 - accuracy: 0.6573 - val_loss: 0.8765 - val_accuracy: 0.6307\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.6885 - accuracy: 0.7422 - val_loss: 0.6864 - val_accuracy: 0.7352\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.5782 - accuracy: 0.7912 - val_loss: 0.4571 - val_accuracy: 0.8580\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4942 - accuracy: 0.8303 - val_loss: 0.5360 - val_accuracy: 0.8273\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4558 - accuracy: 0.8472 - val_loss: 0.8146 - val_accuracy: 0.7023\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.4130 - accuracy: 0.8630 - val_loss: 0.4479 - val_accuracy: 0.8534\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3863 - accuracy: 0.8735 - val_loss: 0.5473 - val_accuracy: 0.8148\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3622 - accuracy: 0.8820 - val_loss: 0.4390 - val_accuracy: 0.8750\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3528 - accuracy: 0.8818 - val_loss: 0.3951 - val_accuracy: 0.8750\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3452 - accuracy: 0.8865 - val_loss: 0.4002 - val_accuracy: 0.8795\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3355 - accuracy: 0.8919 - val_loss: 0.3822 - val_accuracy: 0.8795\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3123 - accuracy: 0.9005 - val_loss: 0.3874 - val_accuracy: 0.8727\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2919 - accuracy: 0.9081 - val_loss: 0.3625 - val_accuracy: 0.8830\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3030 - accuracy: 0.9000 - val_loss: 0.3959 - val_accuracy: 0.8739\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2763 - accuracy: 0.9073 - val_loss: 0.3381 - val_accuracy: 0.8909\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2783 - accuracy: 0.9111 - val_loss: 0.3948 - val_accuracy: 0.8830\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2784 - accuracy: 0.9076 - val_loss: 0.3649 - val_accuracy: 0.8898\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2635 - accuracy: 0.9164 - val_loss: 0.3470 - val_accuracy: 0.8886\n",
            "Accuracy on own dev set: 0.889\n",
            "Accuracy on own test set: 0.896\n",
            "---------------------------\n",
            "0.03\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 1.7212 - accuracy: 0.2635 - val_loss: 1.6576 - val_accuracy: 0.2841\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.2818 - accuracy: 0.4803 - val_loss: 1.0211 - val_accuracy: 0.5602\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8506 - accuracy: 0.6810 - val_loss: 0.9305 - val_accuracy: 0.6841\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.6255 - accuracy: 0.7858 - val_loss: 0.6023 - val_accuracy: 0.7966\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 3s 11ms/step - loss: 0.5317 - accuracy: 0.8270 - val_loss: 0.4697 - val_accuracy: 0.8648\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 3s 10ms/step - loss: 0.4845 - accuracy: 0.8400 - val_loss: 0.4254 - val_accuracy: 0.8739\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.5051 - accuracy: 0.8486 - val_loss: 0.4801 - val_accuracy: 0.8523\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.4291 - accuracy: 0.8675 - val_loss: 0.4783 - val_accuracy: 0.8545\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.4154 - accuracy: 0.8780 - val_loss: 0.3726 - val_accuracy: 0.8932\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3880 - accuracy: 0.8820 - val_loss: 0.6264 - val_accuracy: 0.8193\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3721 - accuracy: 0.8891 - val_loss: 0.3652 - val_accuracy: 0.9000\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3718 - accuracy: 0.8863 - val_loss: 0.3807 - val_accuracy: 0.8864\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3413 - accuracy: 0.8953 - val_loss: 0.3756 - val_accuracy: 0.8886\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3273 - accuracy: 0.9021 - val_loss: 0.3749 - val_accuracy: 0.8932\n",
            "Accuracy on own dev set: 0.893\n",
            "Accuracy on own test set: 0.893\n",
            "---------------------------\n",
            "0.07\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 1.6110 - accuracy: 0.3109 - val_loss: 1.1057 - val_accuracy: 0.5852\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.0597 - accuracy: 0.5889 - val_loss: 0.6920 - val_accuracy: 0.7727\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8104 - accuracy: 0.7339 - val_loss: 1.1064 - val_accuracy: 0.6148\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.9243 - accuracy: 0.6855 - val_loss: 0.8592 - val_accuracy: 0.7273\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.7964 - accuracy: 0.7493 - val_loss: 0.6127 - val_accuracy: 0.8318\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.7447 - accuracy: 0.7649 - val_loss: 1.1413 - val_accuracy: 0.7080\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8214 - accuracy: 0.7237 - val_loss: 1.1139 - val_accuracy: 0.6705\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8343 - accuracy: 0.7088 - val_loss: 0.9171 - val_accuracy: 0.6773\n",
            "Accuracy on own dev set: 0.677\n",
            "Accuracy on own test set: 0.646\n",
            "---------------------------\n",
            "0.1\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 1.5395 - accuracy: 0.3486 - val_loss: 1.0398 - val_accuracy: 0.5841\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.0866 - accuracy: 0.6002 - val_loss: 0.8570 - val_accuracy: 0.7057\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8563 - accuracy: 0.7142 - val_loss: 0.7368 - val_accuracy: 0.7398\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.0258 - accuracy: 0.6457 - val_loss: 0.7830 - val_accuracy: 0.7159\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.0227 - accuracy: 0.6341 - val_loss: 0.9251 - val_accuracy: 0.6705\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.0331 - accuracy: 0.6339 - val_loss: 0.7276 - val_accuracy: 0.7739\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.2194 - accuracy: 0.5538 - val_loss: 1.0301 - val_accuracy: 0.6170\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.1735 - accuracy: 0.5469 - val_loss: 0.7479 - val_accuracy: 0.7307\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.6304 - accuracy: 0.7867 - val_loss: 0.5778 - val_accuracy: 0.8159\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 3s 10ms/step - loss: 0.4541 - accuracy: 0.8479 - val_loss: 0.5836 - val_accuracy: 0.8125\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4095 - accuracy: 0.8661 - val_loss: 0.4025 - val_accuracy: 0.8761\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3564 - accuracy: 0.8836 - val_loss: 0.3928 - val_accuracy: 0.8761\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3307 - accuracy: 0.8917 - val_loss: 0.4108 - val_accuracy: 0.8739\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3050 - accuracy: 0.9005 - val_loss: 0.4162 - val_accuracy: 0.8795\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2945 - accuracy: 0.9028 - val_loss: 0.3759 - val_accuracy: 0.8818\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2782 - accuracy: 0.9066 - val_loss: 0.3438 - val_accuracy: 0.8932\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2649 - accuracy: 0.9083 - val_loss: 0.3739 - val_accuracy: 0.8886\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2427 - accuracy: 0.9192 - val_loss: 0.3316 - val_accuracy: 0.9023\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2332 - accuracy: 0.9209 - val_loss: 0.3546 - val_accuracy: 0.8920\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2156 - accuracy: 0.9258 - val_loss: 0.3300 - val_accuracy: 0.9034\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2008 - accuracy: 0.9310 - val_loss: 0.3620 - val_accuracy: 0.8966\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.1962 - accuracy: 0.9339 - val_loss: 0.3519 - val_accuracy: 0.8898\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.1884 - accuracy: 0.9372 - val_loss: 0.3300 - val_accuracy: 0.9023\n",
            "Accuracy on own dev set: 0.902\n",
            "Accuracy on own test set: 0.906\n",
            "---------------------------\n",
            "0.2\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 1.5168 - accuracy: 0.3806 - val_loss: 1.4873 - val_accuracy: 0.5023\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.3911 - accuracy: 0.4621 - val_loss: 0.9367 - val_accuracy: 0.6193\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.1994 - accuracy: 0.5661 - val_loss: 1.1019 - val_accuracy: 0.5330\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.0618 - accuracy: 0.6308 - val_loss: 0.8487 - val_accuracy: 0.6739\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.7913 - accuracy: 0.7509 - val_loss: 0.7065 - val_accuracy: 0.7682\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8741 - accuracy: 0.7178 - val_loss: 1.0719 - val_accuracy: 0.5375\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.6120 - accuracy: 0.8026 - val_loss: 0.6273 - val_accuracy: 0.7795\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.7882 - accuracy: 0.7502 - val_loss: 0.5789 - val_accuracy: 0.8193\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.5024 - accuracy: 0.8363 - val_loss: 0.4704 - val_accuracy: 0.8261\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3898 - accuracy: 0.8773 - val_loss: 0.5274 - val_accuracy: 0.8318\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3419 - accuracy: 0.8865 - val_loss: 0.3602 - val_accuracy: 0.8818\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2944 - accuracy: 0.9092 - val_loss: 0.3618 - val_accuracy: 0.8932\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2792 - accuracy: 0.9083 - val_loss: 0.3576 - val_accuracy: 0.8943\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2488 - accuracy: 0.9216 - val_loss: 0.3688 - val_accuracy: 0.8989\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2408 - accuracy: 0.9166 - val_loss: 0.3630 - val_accuracy: 0.8989\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2152 - accuracy: 0.9329 - val_loss: 0.3407 - val_accuracy: 0.9011\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2034 - accuracy: 0.9334 - val_loss: 0.3375 - val_accuracy: 0.9000\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1774 - accuracy: 0.9427 - val_loss: 0.3382 - val_accuracy: 0.9023\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1654 - accuracy: 0.9464 - val_loss: 0.3477 - val_accuracy: 0.9114\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1525 - accuracy: 0.9512 - val_loss: 0.3308 - val_accuracy: 0.9125\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1431 - accuracy: 0.9557 - val_loss: 0.3520 - val_accuracy: 0.9057\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1310 - accuracy: 0.9595 - val_loss: 0.3645 - val_accuracy: 0.9080\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1373 - accuracy: 0.9550 - val_loss: 0.3552 - val_accuracy: 0.9068\n",
            "Accuracy on own dev set: 0.907\n",
            "Accuracy on own test set: 0.899\n",
            "---------------------------\n",
            "0.5\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 1.7856 - accuracy: 0.2675 - val_loss: 1.2796 - val_accuracy: 0.5136\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.4672 - accuracy: 0.4377 - val_loss: 1.2056 - val_accuracy: 0.5420\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.3797 - accuracy: 0.4661 - val_loss: 0.8285 - val_accuracy: 0.6943\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.6067 - accuracy: 0.7964 - val_loss: 0.4942 - val_accuracy: 0.8466\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4382 - accuracy: 0.8552 - val_loss: 0.3953 - val_accuracy: 0.8852\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3701 - accuracy: 0.8780 - val_loss: 0.3980 - val_accuracy: 0.8773\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3265 - accuracy: 0.8889 - val_loss: 0.3527 - val_accuracy: 0.8966\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2909 - accuracy: 0.8976 - val_loss: 0.3778 - val_accuracy: 0.8807\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2721 - accuracy: 0.9095 - val_loss: 0.3714 - val_accuracy: 0.8875\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2408 - accuracy: 0.9190 - val_loss: 0.3979 - val_accuracy: 0.8773\n",
            "Accuracy on own dev set: 0.877\n",
            "Accuracy on own test set: 0.868\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix, lr):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = lr\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lrs = [0.01, 0.003, 0.007, 0.005]\n",
        "for lr in lrs:\n",
        "  print(lr)\n",
        "  print(\"---\")\n",
        "  # Create model\n",
        "  model = create_model(Y_train, emb_matrix, lr)\n",
        "  # Train the model\n",
        "  model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "  # Finally do the predictions\n",
        "  test_set_predict(model, X_test_vect, Y_test_bin, \"test\")\n",
        "  print(\"---------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4hd9C9xw4hn",
        "outputId": "81679807-457e-4216-88ee-ace399180343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 1.7765 - accuracy: 0.2076 - val_loss: 1.7520 - val_accuracy: 0.3080\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7180 - accuracy: 0.3265 - val_loss: 1.6597 - val_accuracy: 0.3784\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.4581 - accuracy: 0.3950 - val_loss: 1.2947 - val_accuracy: 0.5239\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.2655 - accuracy: 0.4770 - val_loss: 1.1697 - val_accuracy: 0.4375\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.0898 - accuracy: 0.5564 - val_loss: 0.9475 - val_accuracy: 0.6534\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.8702 - accuracy: 0.6547 - val_loss: 1.0016 - val_accuracy: 0.5625\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.6909 - accuracy: 0.7424 - val_loss: 0.6914 - val_accuracy: 0.7307\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.5787 - accuracy: 0.7896 - val_loss: 0.4581 - val_accuracy: 0.8545\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.4948 - accuracy: 0.8308 - val_loss: 0.5373 - val_accuracy: 0.8273\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4560 - accuracy: 0.8472 - val_loss: 0.8327 - val_accuracy: 0.6909\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4140 - accuracy: 0.8628 - val_loss: 0.4479 - val_accuracy: 0.8545\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3861 - accuracy: 0.8725 - val_loss: 0.5561 - val_accuracy: 0.8102\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3628 - accuracy: 0.8803 - val_loss: 0.4379 - val_accuracy: 0.8739\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3526 - accuracy: 0.8810 - val_loss: 0.3975 - val_accuracy: 0.8750\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3451 - accuracy: 0.8865 - val_loss: 0.4021 - val_accuracy: 0.8795\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3356 - accuracy: 0.8924 - val_loss: 0.3838 - val_accuracy: 0.8795\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3128 - accuracy: 0.8991 - val_loss: 0.3925 - val_accuracy: 0.8716\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2925 - accuracy: 0.9078 - val_loss: 0.3539 - val_accuracy: 0.8864\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3022 - accuracy: 0.8995 - val_loss: 0.3951 - val_accuracy: 0.8727\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2761 - accuracy: 0.9078 - val_loss: 0.3387 - val_accuracy: 0.8898\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2776 - accuracy: 0.9121 - val_loss: 0.3964 - val_accuracy: 0.8830\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2779 - accuracy: 0.9064 - val_loss: 0.3645 - val_accuracy: 0.8886\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 2s 9ms/step - loss: 0.2625 - accuracy: 0.9171 - val_loss: 0.3466 - val_accuracy: 0.8864\n",
            "Accuracy on own dev set: 0.886\n",
            "Accuracy on own test set: 0.892\n",
            "---------------------------\n",
            "0.003\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 1.7895 - accuracy: 0.1844 - val_loss: 1.7811 - val_accuracy: 0.2136\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.7770 - accuracy: 0.2204 - val_loss: 1.7695 - val_accuracy: 0.2318\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7645 - accuracy: 0.2618 - val_loss: 1.7573 - val_accuracy: 0.2852\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.7515 - accuracy: 0.2912 - val_loss: 1.7445 - val_accuracy: 0.3250\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.7369 - accuracy: 0.3341 - val_loss: 1.7278 - val_accuracy: 0.3182\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.7192 - accuracy: 0.3500 - val_loss: 1.7074 - val_accuracy: 0.4011\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.6964 - accuracy: 0.3891 - val_loss: 1.6766 - val_accuracy: 0.4284\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.6481 - accuracy: 0.4192 - val_loss: 1.5997 - val_accuracy: 0.4455\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.4486 - accuracy: 0.4656 - val_loss: 1.3353 - val_accuracy: 0.4932\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.2666 - accuracy: 0.4991 - val_loss: 1.2196 - val_accuracy: 0.4898\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.1411 - accuracy: 0.5457 - val_loss: 1.2319 - val_accuracy: 0.4250\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.0293 - accuracy: 0.5801 - val_loss: 0.9519 - val_accuracy: 0.6489\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.9179 - accuracy: 0.6318 - val_loss: 1.0005 - val_accuracy: 0.6716\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8717 - accuracy: 0.6597 - val_loss: 0.8499 - val_accuracy: 0.6432\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.7971 - accuracy: 0.7078 - val_loss: 0.7486 - val_accuracy: 0.7216\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 2s 9ms/step - loss: 0.7454 - accuracy: 0.7216 - val_loss: 0.7267 - val_accuracy: 0.7102\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 3s 11ms/step - loss: 0.6861 - accuracy: 0.7566 - val_loss: 0.6130 - val_accuracy: 0.8000\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.6187 - accuracy: 0.7791 - val_loss: 0.6014 - val_accuracy: 0.8034\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.5715 - accuracy: 0.8000 - val_loss: 0.5068 - val_accuracy: 0.8295\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.5384 - accuracy: 0.8130 - val_loss: 0.5081 - val_accuracy: 0.8330\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.5069 - accuracy: 0.8246 - val_loss: 0.6754 - val_accuracy: 0.7523\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.4894 - accuracy: 0.8306 - val_loss: 0.5816 - val_accuracy: 0.8057\n",
            "Accuracy on own dev set: 0.806\n",
            "Accuracy on own test set: 0.798\n",
            "---------------------------\n",
            "0.007\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 1.7850 - accuracy: 0.1927 - val_loss: 1.7667 - val_accuracy: 0.2682\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7535 - accuracy: 0.2739 - val_loss: 1.7322 - val_accuracy: 0.2943\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7020 - accuracy: 0.3419 - val_loss: 1.6359 - val_accuracy: 0.4159\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.4449 - accuracy: 0.4154 - val_loss: 1.3163 - val_accuracy: 0.3739\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.2751 - accuracy: 0.4732 - val_loss: 1.1963 - val_accuracy: 0.4466\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 9ms/step - loss: 1.2072 - accuracy: 0.5043 - val_loss: 1.1383 - val_accuracy: 0.5625\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.0836 - accuracy: 0.5763 - val_loss: 1.0065 - val_accuracy: 0.6420\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8818 - accuracy: 0.6637 - val_loss: 0.7750 - val_accuracy: 0.7193\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.7253 - accuracy: 0.7310 - val_loss: 0.8961 - val_accuracy: 0.6682\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.6036 - accuracy: 0.7891 - val_loss: 0.8538 - val_accuracy: 0.6852\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.5200 - accuracy: 0.8220 - val_loss: 0.5269 - val_accuracy: 0.8341\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4776 - accuracy: 0.8377 - val_loss: 0.4697 - val_accuracy: 0.8352\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.4323 - accuracy: 0.8550 - val_loss: 0.5117 - val_accuracy: 0.8409\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4102 - accuracy: 0.8585 - val_loss: 0.4292 - val_accuracy: 0.8670\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3823 - accuracy: 0.8770 - val_loss: 0.4063 - val_accuracy: 0.8659\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3726 - accuracy: 0.8730 - val_loss: 0.4034 - val_accuracy: 0.8670\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3460 - accuracy: 0.8836 - val_loss: 0.3695 - val_accuracy: 0.8773\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3381 - accuracy: 0.8893 - val_loss: 0.3650 - val_accuracy: 0.8807\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3252 - accuracy: 0.8908 - val_loss: 0.3847 - val_accuracy: 0.8761\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3087 - accuracy: 0.8995 - val_loss: 0.3698 - val_accuracy: 0.8909\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2997 - accuracy: 0.9005 - val_loss: 0.4575 - val_accuracy: 0.8557\n",
            "Accuracy on own dev set: 0.856\n",
            "Accuracy on own test set: 0.859\n",
            "---------------------------\n",
            "0.005\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 1.7881 - accuracy: 0.1810 - val_loss: 1.7733 - val_accuracy: 0.2170\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7629 - accuracy: 0.2495 - val_loss: 1.7519 - val_accuracy: 0.2489\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7386 - accuracy: 0.3028 - val_loss: 1.7232 - val_accuracy: 0.3693\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.6953 - accuracy: 0.3706 - val_loss: 1.6570 - val_accuracy: 0.3830\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.4751 - accuracy: 0.4111 - val_loss: 1.2807 - val_accuracy: 0.4000\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.2953 - accuracy: 0.4533 - val_loss: 1.2273 - val_accuracy: 0.4977\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.2402 - accuracy: 0.4720 - val_loss: 1.2708 - val_accuracy: 0.5193\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 1.1748 - accuracy: 0.5230 - val_loss: 1.1319 - val_accuracy: 0.5193\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.1113 - accuracy: 0.5528 - val_loss: 1.0313 - val_accuracy: 0.5511\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.9720 - accuracy: 0.6140 - val_loss: 0.8305 - val_accuracy: 0.6784\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.8430 - accuracy: 0.6737 - val_loss: 1.2723 - val_accuracy: 0.4739\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.7304 - accuracy: 0.7296 - val_loss: 0.5953 - val_accuracy: 0.7955\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.6076 - accuracy: 0.7794 - val_loss: 0.4944 - val_accuracy: 0.8352\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.5331 - accuracy: 0.8116 - val_loss: 0.5642 - val_accuracy: 0.8159\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4901 - accuracy: 0.8322 - val_loss: 0.5075 - val_accuracy: 0.8364\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4599 - accuracy: 0.8405 - val_loss: 0.4456 - val_accuracy: 0.8511\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4257 - accuracy: 0.8571 - val_loss: 0.3844 - val_accuracy: 0.8886\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3976 - accuracy: 0.8687 - val_loss: 0.4345 - val_accuracy: 0.8580\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3871 - accuracy: 0.8673 - val_loss: 0.4268 - val_accuracy: 0.8580\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3630 - accuracy: 0.8806 - val_loss: 0.3549 - val_accuracy: 0.8898\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3537 - accuracy: 0.8855 - val_loss: 0.3905 - val_accuracy: 0.8739\n",
            "Epoch 22/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.3419 - accuracy: 0.8877 - val_loss: 0.3669 - val_accuracy: 0.8795\n",
            "Epoch 23/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3262 - accuracy: 0.8924 - val_loss: 0.3458 - val_accuracy: 0.8875\n",
            "Epoch 24/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3110 - accuracy: 0.9000 - val_loss: 0.4216 - val_accuracy: 0.8705\n",
            "Epoch 25/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3154 - accuracy: 0.8915 - val_loss: 0.3888 - val_accuracy: 0.8693\n",
            "Epoch 26/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 0.2921 - accuracy: 0.9066 - val_loss: 0.4236 - val_accuracy: 0.8614\n",
            "Accuracy on own dev set: 0.861\n",
            "Accuracy on own test set: 0.859\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adam Optimizer"
      ],
      "metadata": {
        "id": "i-yhmXxwI2w9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix, lr):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = lr\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = Adam(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lrs = [0.01, 0.03, 0.07, 0.1, 0.2, 0.5]\n",
        "for lr in lrs:\n",
        "  print(lr)\n",
        "  print(\"---\")\n",
        "  # Create model\n",
        "  model = create_model(Y_train, emb_matrix, lr)\n",
        "  # Train the model\n",
        "  model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "  # Finally do the predictions\n",
        "  test_set_predict(model, X_test_vect, Y_test_bin, \"test\")\n",
        "  print(\"---------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr_HNfHBvxE9",
        "outputId": "6fb070e0-2a53-4d5b-de0d-62849564a169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 5s 10ms/step - loss: 0.8057 - accuracy: 0.7045 - val_loss: 0.4075 - val_accuracy: 0.8773\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3998 - accuracy: 0.8621 - val_loss: 0.3684 - val_accuracy: 0.8795\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3517 - accuracy: 0.8813 - val_loss: 0.4056 - val_accuracy: 0.8841\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3476 - accuracy: 0.8810 - val_loss: 0.4176 - val_accuracy: 0.8682\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3388 - accuracy: 0.8848 - val_loss: 0.4143 - val_accuracy: 0.8659\n",
            "Accuracy on own dev set: 0.866\n",
            "Accuracy on own test set: 0.881\n",
            "---------------------------\n",
            "0.03\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 1.8988 - accuracy: 0.2209 - val_loss: 1.6695 - val_accuracy: 0.2739\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7670 - accuracy: 0.2514 - val_loss: 1.8156 - val_accuracy: 0.3080\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7079 - accuracy: 0.2709 - val_loss: 1.5994 - val_accuracy: 0.3000\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.6898 - accuracy: 0.2770 - val_loss: 1.6791 - val_accuracy: 0.3102\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.7032 - accuracy: 0.2936 - val_loss: 1.5484 - val_accuracy: 0.3205\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 9ms/step - loss: 1.6674 - accuracy: 0.2924 - val_loss: 1.8454 - val_accuracy: 0.3057\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 3s 10ms/step - loss: 1.6682 - accuracy: 0.3095 - val_loss: 1.5420 - val_accuracy: 0.3170\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.6262 - accuracy: 0.3121 - val_loss: 1.7273 - val_accuracy: 0.3102\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.6567 - accuracy: 0.3024 - val_loss: 1.5726 - val_accuracy: 0.3136\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 1.6689 - accuracy: 0.3123 - val_loss: 1.6069 - val_accuracy: 0.3125\n",
            "Accuracy on own dev set: 0.312\n",
            "Accuracy on own test set: 0.289\n",
            "---------------------------\n",
            "0.07\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 2.5252 - accuracy: 0.1633 - val_loss: 2.1648 - val_accuracy: 0.1705\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 2.3695 - accuracy: 0.1810 - val_loss: 1.9978 - val_accuracy: 0.1784\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 11ms/step - loss: 2.5727 - accuracy: 0.1791 - val_loss: 2.9719 - val_accuracy: 0.1670\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 9ms/step - loss: 2.2851 - accuracy: 0.1848 - val_loss: 2.4731 - val_accuracy: 0.1716\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 2.4056 - accuracy: 0.1739 - val_loss: 2.5792 - val_accuracy: 0.1818\n",
            "Accuracy on own dev set: 0.182\n",
            "Accuracy on own test set: 0.18\n",
            "---------------------------\n",
            "0.1\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 2.5196 - accuracy: 0.1848 - val_loss: 2.0484 - val_accuracy: 0.2364\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 2.4126 - accuracy: 0.1877 - val_loss: 2.0713 - val_accuracy: 0.1875\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 9ms/step - loss: 2.7958 - accuracy: 0.1709 - val_loss: 3.1678 - val_accuracy: 0.1659\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 2.3453 - accuracy: 0.1782 - val_loss: 2.3897 - val_accuracy: 0.1716\n",
            "Accuracy on own dev set: 0.172\n",
            "Accuracy on own test set: 0.183\n",
            "---------------------------\n",
            "0.2\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 5.3498 - accuracy: 0.1685 - val_loss: 3.0882 - val_accuracy: 0.1682\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 5.0322 - accuracy: 0.1685 - val_loss: 3.9855 - val_accuracy: 0.1648\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 5.4490 - accuracy: 0.1682 - val_loss: 3.7676 - val_accuracy: 0.1716\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 3.5422 - accuracy: 0.1716 - val_loss: 3.8367 - val_accuracy: 0.1670\n",
            "Accuracy on own dev set: 0.167\n",
            "Accuracy on own test set: 0.164\n",
            "---------------------------\n",
            "0.5\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 16.2689 - accuracy: 0.1867 - val_loss: 14.2107 - val_accuracy: 0.1625\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 16.5593 - accuracy: 0.1699 - val_loss: 9.0234 - val_accuracy: 0.1716\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 10ms/step - loss: 14.2509 - accuracy: 0.1737 - val_loss: 15.6886 - val_accuracy: 0.1750\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 14.3001 - accuracy: 0.1652 - val_loss: 8.3977 - val_accuracy: 0.1636\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 11.9490 - accuracy: 0.1637 - val_loss: 5.4294 - val_accuracy: 0.1693\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 7ms/step - loss: 15.1149 - accuracy: 0.1694 - val_loss: 20.5030 - val_accuracy: 0.1682\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 16.2311 - accuracy: 0.1623 - val_loss: 22.9996 - val_accuracy: 0.1625\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 16.2217 - accuracy: 0.1682 - val_loss: 12.6595 - val_accuracy: 0.1727\n",
            "Accuracy on own dev set: 0.173\n",
            "Accuracy on own test set: 0.161\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix, lr):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = lr\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = Adam(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(LSTM(embedding_dim, dropout=0.35))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lrs = [0.01, 0.003, 0.007, 0.005]\n",
        "for lr in lrs:\n",
        "  print(lr)\n",
        "  print(\"---\")\n",
        "  # Create model\n",
        "  model = create_model(Y_train, emb_matrix, lr)\n",
        "  # Train the model\n",
        "  model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "  # Finally do the predictions\n",
        "  test_set_predict(model, X_test_vect, Y_test_bin, \"test\")\n",
        "  print(\"---------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4YK-atrwV41",
        "outputId": "669b0ab3-1d21-46aa-a295-edef6758647e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 0.8163 - accuracy: 0.6945 - val_loss: 0.3964 - val_accuracy: 0.8795\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3844 - accuracy: 0.8735 - val_loss: 0.4384 - val_accuracy: 0.8716\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3668 - accuracy: 0.8787 - val_loss: 0.3885 - val_accuracy: 0.8795\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3643 - accuracy: 0.8739 - val_loss: 0.3987 - val_accuracy: 0.8750\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3535 - accuracy: 0.8822 - val_loss: 0.4481 - val_accuracy: 0.8693\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3341 - accuracy: 0.8808 - val_loss: 0.4045 - val_accuracy: 0.8761\n",
            "Accuracy on own dev set: 0.876\n",
            "Accuracy on own test set: 0.863\n",
            "---------------------------\n",
            "0.003\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 1.0892 - accuracy: 0.5742 - val_loss: 0.5043 - val_accuracy: 0.8500\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.4139 - accuracy: 0.8621 - val_loss: 0.3993 - val_accuracy: 0.8750\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3159 - accuracy: 0.8993 - val_loss: 0.3410 - val_accuracy: 0.9068\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2613 - accuracy: 0.9133 - val_loss: 0.3685 - val_accuracy: 0.8920\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2098 - accuracy: 0.9296 - val_loss: 0.3198 - val_accuracy: 0.9068\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1848 - accuracy: 0.9391 - val_loss: 0.3544 - val_accuracy: 0.9080\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1563 - accuracy: 0.9464 - val_loss: 0.3575 - val_accuracy: 0.8966\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1397 - accuracy: 0.9502 - val_loss: 0.3442 - val_accuracy: 0.9045\n",
            "Accuracy on own dev set: 0.905\n",
            "Accuracy on own test set: 0.894\n",
            "---------------------------\n",
            "0.007\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 9ms/step - loss: 0.9513 - accuracy: 0.6336 - val_loss: 0.3909 - val_accuracy: 0.8852\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3860 - accuracy: 0.8718 - val_loss: 0.3963 - val_accuracy: 0.8784\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3226 - accuracy: 0.8943 - val_loss: 0.3784 - val_accuracy: 0.8852\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2879 - accuracy: 0.9062 - val_loss: 0.4128 - val_accuracy: 0.8852\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2675 - accuracy: 0.9078 - val_loss: 0.3859 - val_accuracy: 0.8932\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2563 - accuracy: 0.9104 - val_loss: 0.4111 - val_accuracy: 0.8795\n",
            "Accuracy on own dev set: 0.88\n",
            "Accuracy on own test set: 0.88\n",
            "---------------------------\n",
            "0.005\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 4s 10ms/step - loss: 0.9280 - accuracy: 0.6581 - val_loss: 0.4381 - val_accuracy: 0.8693\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.3662 - accuracy: 0.8794 - val_loss: 0.3673 - val_accuracy: 0.8864\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 11ms/step - loss: 0.2759 - accuracy: 0.9071 - val_loss: 0.4004 - val_accuracy: 0.8795\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.2416 - accuracy: 0.9190 - val_loss: 0.3392 - val_accuracy: 0.9011\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1935 - accuracy: 0.9391 - val_loss: 0.3640 - val_accuracy: 0.9011\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1775 - accuracy: 0.9389 - val_loss: 0.3981 - val_accuracy: 0.8909\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 2s 8ms/step - loss: 0.1589 - accuracy: 0.9460 - val_loss: 0.4082 - val_accuracy: 0.8977\n",
            "Accuracy on own dev set: 0.898\n",
            "Accuracy on own test set: 0.884\n",
            "---------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 7: Bi-directional LSTM"
      ],
      "metadata": {
        "id": "iOrk7_gQUMDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "python_random.seed(1234)\n",
        "\n",
        "def create_model(Y_train, emb_matrix, lr):\n",
        "    '''Create the Keras model to use'''\n",
        "    # Define settings, you might want to create cmd line args for them\n",
        "    learning_rate = lr\n",
        "    loss_function = 'categorical_crossentropy'\n",
        "    optim = SGD(learning_rate=learning_rate)\n",
        "    # Take embedding dim and size from emb_matrix\n",
        "    embedding_dim = len(emb_matrix[0])\n",
        "    num_tokens = len(emb_matrix)\n",
        "    num_labels = len(set(Y_train))\n",
        "    # Now build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
        "    # Here you should add LSTM layers (and potentially dropout)\n",
        "    model.add(Dense(embedding_dim, activation=\"relu\"))\n",
        "    model.add(Bidirectional(LSTM(embedding_dim, dropout=0.35)))\n",
        "    # Ultimately, end with dense layer with softmax\n",
        "    model.add(Dense(input_dim=embedding_dim, units=num_labels, activation=\"softmax\"))\n",
        "    # Compile model using our settings, check for accuracy\n",
        "    model.compile(loss=loss_function, optimizer=optim, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lrs = [0.01, 0.03, 0.07, 0.1, 0.2, 0.5]\n",
        "for lr in lrs:\n",
        "  print(lr)\n",
        "  print(\"---\")\n",
        "  # Create model\n",
        "  model = create_model(Y_train, emb_matrix, lr)\n",
        "  # Train the model\n",
        "  model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 16, 50)\n",
        "  # Finally do the predictions\n",
        "  test_set_predict(model, X_test_vect, Y_test_bin, \"test\")\n",
        "  print(\"---------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5HDsVmjzBQO",
        "outputId": "ad74fedb-b64c-4cad-8bfd-b6dbd703ca78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 7s 15ms/step - loss: 1.7575 - accuracy: 0.2595 - val_loss: 1.7125 - val_accuracy: 0.4205\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 1.6716 - accuracy: 0.4386 - val_loss: 1.5841 - val_accuracy: 0.5205\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 1.3863 - accuracy: 0.5415 - val_loss: 1.2195 - val_accuracy: 0.6568\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 1.0862 - accuracy: 0.6092 - val_loss: 0.8452 - val_accuracy: 0.7091\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.8482 - accuracy: 0.6874 - val_loss: 0.6690 - val_accuracy: 0.7625\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.6852 - accuracy: 0.7576 - val_loss: 0.5685 - val_accuracy: 0.7989\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.5568 - accuracy: 0.8066 - val_loss: 0.5277 - val_accuracy: 0.8125\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.4804 - accuracy: 0.8315 - val_loss: 0.4402 - val_accuracy: 0.8557\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.4260 - accuracy: 0.8536 - val_loss: 0.4709 - val_accuracy: 0.8375\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3908 - accuracy: 0.8697 - val_loss: 0.7844 - val_accuracy: 0.6989\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3620 - accuracy: 0.8789 - val_loss: 0.4254 - val_accuracy: 0.8659\n",
            "Epoch 12/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3436 - accuracy: 0.8855 - val_loss: 0.3458 - val_accuracy: 0.8898\n",
            "Epoch 13/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3242 - accuracy: 0.8903 - val_loss: 0.3730 - val_accuracy: 0.8795\n",
            "Epoch 14/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3085 - accuracy: 0.8967 - val_loss: 0.3839 - val_accuracy: 0.8773\n",
            "Epoch 15/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2978 - accuracy: 0.9009 - val_loss: 0.3382 - val_accuracy: 0.8932\n",
            "Epoch 16/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2874 - accuracy: 0.9045 - val_loss: 0.3370 - val_accuracy: 0.8932\n",
            "Epoch 17/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2720 - accuracy: 0.9085 - val_loss: 0.3522 - val_accuracy: 0.8909\n",
            "Epoch 18/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2710 - accuracy: 0.9062 - val_loss: 0.3124 - val_accuracy: 0.9057\n",
            "Epoch 19/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2582 - accuracy: 0.9118 - val_loss: 0.3331 - val_accuracy: 0.8977\n",
            "Epoch 20/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2447 - accuracy: 0.9152 - val_loss: 0.3283 - val_accuracy: 0.8966\n",
            "Epoch 21/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2351 - accuracy: 0.9192 - val_loss: 0.3286 - val_accuracy: 0.8920\n",
            "Accuracy on own dev set: 0.892\n",
            "Accuracy on own test set: 0.906\n",
            "---------------------------\n",
            "0.03\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 8s 19ms/step - loss: 1.6421 - accuracy: 0.3265 - val_loss: 1.2389 - val_accuracy: 0.5966\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 1.0934 - accuracy: 0.5953 - val_loss: 0.7230 - val_accuracy: 0.8091\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.6337 - accuracy: 0.7744 - val_loss: 0.5741 - val_accuracy: 0.8057\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.4288 - accuracy: 0.8498 - val_loss: 0.4093 - val_accuracy: 0.8784\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3800 - accuracy: 0.8685 - val_loss: 0.3565 - val_accuracy: 0.8932\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3492 - accuracy: 0.8791 - val_loss: 0.3357 - val_accuracy: 0.9000\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3122 - accuracy: 0.8936 - val_loss: 0.3513 - val_accuracy: 0.8989\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3003 - accuracy: 0.8991 - val_loss: 0.3745 - val_accuracy: 0.8932\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2718 - accuracy: 0.9064 - val_loss: 0.4039 - val_accuracy: 0.8807\n",
            "Accuracy on own dev set: 0.881\n",
            "Accuracy on own test set: 0.88\n",
            "---------------------------\n",
            "0.07\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 6s 15ms/step - loss: 1.4068 - accuracy: 0.4232 - val_loss: 0.7695 - val_accuracy: 0.7261\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.6240 - accuracy: 0.7810 - val_loss: 0.5069 - val_accuracy: 0.8330\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.4155 - accuracy: 0.8618 - val_loss: 0.4036 - val_accuracy: 0.8693\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3484 - accuracy: 0.8799 - val_loss: 0.3647 - val_accuracy: 0.8955\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3161 - accuracy: 0.8922 - val_loss: 0.3309 - val_accuracy: 0.9011\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2932 - accuracy: 0.9005 - val_loss: 0.3388 - val_accuracy: 0.8977\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2718 - accuracy: 0.9104 - val_loss: 0.3354 - val_accuracy: 0.9023\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2638 - accuracy: 0.9102 - val_loss: 0.3221 - val_accuracy: 0.9000\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2254 - accuracy: 0.9239 - val_loss: 0.3839 - val_accuracy: 0.8739\n",
            "Epoch 10/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2148 - accuracy: 0.9294 - val_loss: 0.4614 - val_accuracy: 0.8511\n",
            "Epoch 11/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2009 - accuracy: 0.9334 - val_loss: 0.3664 - val_accuracy: 0.8864\n",
            "Accuracy on own dev set: 0.886\n",
            "Accuracy on own test set: 0.879\n",
            "---------------------------\n",
            "0.1\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 7s 15ms/step - loss: 1.2889 - accuracy: 0.4848 - val_loss: 0.6170 - val_accuracy: 0.7795\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.5264 - accuracy: 0.8223 - val_loss: 0.4312 - val_accuracy: 0.8739\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.4028 - accuracy: 0.8713 - val_loss: 0.3891 - val_accuracy: 0.8807\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3386 - accuracy: 0.8813 - val_loss: 0.3392 - val_accuracy: 0.9023\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3092 - accuracy: 0.8981 - val_loss: 0.3170 - val_accuracy: 0.9091\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2929 - accuracy: 0.9009 - val_loss: 0.3250 - val_accuracy: 0.9000\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2601 - accuracy: 0.9088 - val_loss: 0.3344 - val_accuracy: 0.9080\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2451 - accuracy: 0.9175 - val_loss: 0.3542 - val_accuracy: 0.8909\n",
            "Accuracy on own dev set: 0.891\n",
            "Accuracy on own test set: 0.883\n",
            "---------------------------\n",
            "0.2\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 7s 15ms/step - loss: 1.1124 - accuracy: 0.5706 - val_loss: 0.4906 - val_accuracy: 0.8409\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.4934 - accuracy: 0.8386 - val_loss: 0.5985 - val_accuracy: 0.8159\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3965 - accuracy: 0.8635 - val_loss: 0.3975 - val_accuracy: 0.8898\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3385 - accuracy: 0.8860 - val_loss: 0.3350 - val_accuracy: 0.9023\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3013 - accuracy: 0.8972 - val_loss: 0.3172 - val_accuracy: 0.9034\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2783 - accuracy: 0.9050 - val_loss: 0.3392 - val_accuracy: 0.8955\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2457 - accuracy: 0.9171 - val_loss: 0.3345 - val_accuracy: 0.9057\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2252 - accuracy: 0.9246 - val_loss: 0.3527 - val_accuracy: 0.8943\n",
            "Accuracy on own dev set: 0.894\n",
            "Accuracy on own test set: 0.888\n",
            "---------------------------\n",
            "0.5\n",
            "---\n",
            "Epoch 1/50\n",
            "264/264 [==============================] - 7s 15ms/step - loss: 1.2082 - accuracy: 0.5462 - val_loss: 0.7426 - val_accuracy: 0.7511\n",
            "Epoch 2/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.7551 - accuracy: 0.7547 - val_loss: 1.5338 - val_accuracy: 0.5557\n",
            "Epoch 3/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.5173 - accuracy: 0.8372 - val_loss: 0.6213 - val_accuracy: 0.8023\n",
            "Epoch 4/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.4047 - accuracy: 0.8701 - val_loss: 0.5123 - val_accuracy: 0.8432\n",
            "Epoch 5/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.3393 - accuracy: 0.8863 - val_loss: 0.3557 - val_accuracy: 0.8932\n",
            "Epoch 6/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2813 - accuracy: 0.9111 - val_loss: 0.3535 - val_accuracy: 0.8920\n",
            "Epoch 7/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2302 - accuracy: 0.9282 - val_loss: 0.3908 - val_accuracy: 0.8932\n",
            "Epoch 8/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.2131 - accuracy: 0.9277 - val_loss: 0.3685 - val_accuracy: 0.8977\n",
            "Epoch 9/50\n",
            "264/264 [==============================] - 3s 12ms/step - loss: 0.1797 - accuracy: 0.9441 - val_loss: 0.3864 - val_accuracy: 0.8977\n",
            "Accuracy on own dev set: 0.898\n",
            "Accuracy on own test set: 0.902\n",
            "---------------------------\n"
          ]
        }
      ]
    }
  ]
}